\documentclass[a4paper]{scrartcl}

% font/encoding packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[ngerman]{babel}
\usepackage[ngerman=ngerman-x-latest]{hyphsubst}

\usepackage{amsmath, amssymb, amsfonts, amsthm}
\usepackage{array}
\usepackage{stmaryrd}
\usepackage{marvosym}
\allowdisplaybreaks
\usepackage[output-decimal-marker={,}]{siunitx}
\usepackage[shortlabels]{enumitem}
\usepackage[section]{placeins}
\usepackage{float}
\usepackage{units}
\usepackage{listings}
\usepackage{pgfplots}
\pgfplotsset{compat=1.12}

\newtheorem*{behaupt}{Behauptung}
\newcommand{\gdw}{\Leftrightarrow}
\newcommand{\N}{\mathbb{N}}
\newcommand{\prob}{\mathbb{P}}
\newcommand{\cov}{\operatorname{Cov}}
\newcommand{\e}{\mathbb{E}}
\newcommand{\var}{\operatorname{Var}}
\newcommand{\corr}{\operatorname{Corr}}

\usepackage{fancyhdr}
\pagestyle{fancy}

\def \blattnr {1 }

\lhead{Stochastik 2 - Blatt \blattnr}
\rhead{Florian Abt, Lennart Braun, Sascha Schulz}
\cfoot{\thepage}


\title{Stochastik 2 für Informatiker}
\subtitle{Blatt \blattnr Hausaufgaben}
\author{
    Florian Abt (6524404), \\
    Lennart Braun (6523742), \\
    Sascha Schulz (6434677)
}
\date{zum 20. Oktober 2015}

\begin{document}
\maketitle

\begin{enumerate}[label=\bfseries 1.\arabic*]
    \item
        Die alternative Definition für die geometrische Verteilung sei
        \begin{equation*}
            \text{Geom}_p^0(k) = p(1-p)^k \qquad k \in \mathbb{N}_0 \text{.}
        \end{equation*}
        Es sei $Z$ eine Zufallsvariable mit $Z \sim \text{Geom}_p^0$.
        \begin{enumerate}[label=\alph*)]
            \item
                Die alternative Definition der geometrischen Verteilung
                $\text{Geom}_p^0$ beschreibt die Anzahl der fehlgeschlagenen
                Experimente vor dem ersten erfolgreichen Experiment in einer
                Bernoullikette.

            \item
                Es sei $Y$ eine Zufallsvariable mit $Y \sim \text{Geom}_p$.              
                \begin{equation*}
                    \begin{split}
                        \text{Geom}_p(k)
                        &= p(1-p)^{k-1} \\
                        &= p(1-p)^k \cdot (1-p)^{-1} \\
                        &= \frac{1}{1-p} \cdot p(1-p)^k \\
                        &= \frac{1}{1-p} \cdot \text{Geom}_p^0(k)
                    \end{split}
                \end{equation*}
                Somit lässt sich der Zusammenhang erkennen, dass die
                Verteilungen korrelieren; die Werte von $\text{Geom}_p$ sind
                lediglich um den Faktor $\frac1{1-p}$ zu $\text{Geom}_p^0$
                skaliert.  Dies lässt sich auch wie folgt ausdrücken:
                \begin{equation*}
                    \prob(Z=k) = p(1-p)^{k-1} = \prob(Y=k-1)
                \end{equation*}
        \end{enumerate}

    \item
        Es sei $X \sim \text{Bin}_{n,p}$ eine binomialverteilte Zufallsvariable
        mit den Parametern $n \in \mathbb{N}$ und $p \in [0,1]$.
        \begin{enumerate}[label=\alph*)]
            \item
                Die Zufallsvariablen $X_i$ für $1 \leq i \leq n$, die den
                Ausgang des $i$-ten Experiments anzeigen sind
                bernoulliverteilt.  D.~h. $X_i$ bildet auf $\{0,1\}$ ab und es
                gelten $\prob(X_i=1) = p$ sowie $\prob(X_i=0) = 1-p$
                für alle $1 \leq i \leq n$.

            \item
                Sei $W \sim \text{Bin}_{m,p}$.

                \begin{behaupt}
                    Die Summe zweier binomialverteilten Zufallsvariablen ist
                    wieder binomialverteilt:
                    Es gilt $X + W \sim \text{Bin}_{n+m,p}$.
                \end{behaupt}
                \begin{proof}
                    Die Behauptung lässt sich einmal heuristisch herleiten: $X$
                    bzw. $W$ zeigt die Anzahl der Erfolge in $n$ bzw. $m$
                    unabhängigen Zufallsexperimenten mit der
                    Erfolgswahrscheinlichkeit $p$ an. Daher beschreibt die
                    Summe $X + W$ die Anzahl der Erfolge in $n+m$ unabhängigen
                    Experimenten mit Erfolgswahrscheinlichkeit $p$.

                    Eine andere Möglichkeit:
                    \begin{equation*}
                        \begin{split}
                            \prob(X+W=k)
                            &= \prob \left( \bigcup_{j=0}^k \{X=j \land W=k-j\}
                            \right) \\
                            &= \sum_{j=0}^k \prob (\{X=j \land W=k-j\}) \\
                            &= \sum_{j=0}^k \prob (X=j) \cdot \prob(W=k-j) \\
                            &= \sum_{j=0}^k
                            \binom{n}{j} \cdot p^j \cdot (1-p)^{n-j}
                            \binom{m}{k-j} \cdot p^{k-j} \cdot (1-p)^{m-k+j} \\
                            &= p^k \cdot (1-p)^{n+m-k} \cdot
                            \sum_{j=0}^k \binom{n}{j} \cdot \binom{m}{k-j} \\
                            &= \binom{n+m}{k} \cdot p^k \cdot (1-p)^{n+m-k} \\
                            &= \text{Bin}_{(n+m),p}
                        \end{split}
                    \end{equation*}
                \end{proof}

            \item
                \begin{behaupt}
                    Der Erwartungswert einer binomialverteilten Zufallsvariable
                    $X \sim \text{Bin}_{n,p}$ ist $\e[X] = n \cdot p$.
                \end{behaupt}
                \begin{proof}
                    $X$ lässt sich als Summe von Indikatorzufallsvariablen
                    schreiben, die jeweils den Ausgang eines Elements anzeigen:
                    $X = \sum_{i=1}^n X_i$ mit $X_i \sim \text{Bin}_{1,p}$.
                    Für die $X_i$ gilt jeweils
                    \begin{equation*}
                        \e[X_i] = 0 \cdot \prob(X_i=0) + 1 \cdot \prob(X_i=1)
                        = p \text{ .}
                    \end{equation*}
                    Aus der Linearität des Erwartungswertes folgt:
                    \begin{equation*}
                        \begin{split}
                            \e[X]
                            &= \e\left[\sum_{i=0}^n X_i\right] \\
                            &= \sum_{i=0}^n \e[X_i] \\
                            &= \sum_{i=0}^n p \\
                            &= n \cdot p
                        \end{split}
                    \end{equation*}
                \end{proof}

        \end{enumerate}

    \item
        Ein fairer Würfel wird wiederholt geworfen.
        \begin{enumerate}[label=\alph*)]
            \item
                Die Zufallsvariable $X_n$ sei die Anzahl der Sechsen in den
                ersten $n$ Würfen.

                \begin{behaupt}
                    $(X_n)_{n \in \N_0}$ ist eine DTMC.
                \end{behaupt}
                \begin{proof}
                    Der Zustandsraum ist die Menge der natürlichen Zahlen
                    inklusive der $0$, $\N_0$, da die Zufallsvariablen Anzahlen
                    angeben.

                    Die Wahrscheinlichkeit, dass $X_n$ den Zustand $j \in \N_0$
                    annimmt, ist nur von dem Zustand $X_{n-1}$ abhängig ($n \in
                    \N$).  Dabei unterscheiden wir drei Fälle: Wird im $n$-ten
                    Wurf eine Sechs gewürfelt (Wahrscheinlichkeit
                    $\nicefrac{1}{6}$), wird die Anzahl ewürfelter Sechsen
                    inkrementiert ($X_n = X_{n-1}+1$). Bei allen anderen
                    Augenzahlen (Wahrscheinlichkeit $\nicefrac{5}{6}$) bleibt
                    die Anzahl gewürfelter Sechsen unverändert ($X_n =
                    X_{n-1}$).  Weiterhin kann die Anzahl gewürfelter Sechsen
                    nicht verringert oder um mehr als $1$ erhöht werden.
                    Derartige Übergänge sind also ausgeschlossen.
                    Für die Einschritt-Übergangswahrscheinlichkeiten gilt also
                    \begin{equation*}
                        p_{ij} = \prob(X_1=j \ |\  X_0=i) =
                        \begin{cases}
                            \nicefrac{1}{6} & \text{if } j = i + 1 \\
                            \nicefrac{5}{6} & \text{if } j = i \\
                            0 & \text{else}
                        \end{cases}
                        \qquad
                        \forall i,j \in N_0
                        \text{ .}
                    \end{equation*}
                    Da bei $0$ Würfen noch keine Sechs gefallen sein kann, gilt
                    $\prob(X_0 = 0) = 1$.
                    Damit ist $(X_n)_{n \in \N_0}$ eine Markov-Kette.
                \end{proof}

            \item
                Die Zufallsvariable $X_n$ sei die größte gewürfelte Augenzahl
                während der ersten $n$ Würfe.
                Da ein Maximum über $0$ Ergebnisse nicht wohldefiniert ist,
                betrachten wir die Folge $(X_n)_{n \in \N}$ (ohne $X_0$) und
                untersuchen, ob diese eine DTMC gemäß Definition 1.2.1 ist mit
                der Änderung, dass die Indizes auch mit $1$ beginnen dürfen.

                \begin{behaupt}
                    $(X_n)_{n \in \N}$ ist eine DTMC.
                \end{behaupt}
                \begin{proof}
                    Der Zustandsraum ist $Z = \{1, \dotsc, 6\}$.

                    Die Wahrscheinlichkeit, dass $X_n$ den Zustand $j \in Z$
                    annimmt, ist nur von dem Zustand $X_{n-1}$ abhängig ($n \in
                    \N \land n > 1$).  Es sind wieder drei Fälle zu
                    unterscheiden: Wird eine Zahl kleiner oder gleich dem
                    bisherigen Maximum $i$ gewürfelt (Wahrscheinlichkeit
                    $\nicefrac{i}{6}$) ändert sich das Maximum nicht. Für jede
                    gewürfelte Zahl $j > i$ (jeweils Wahrscheinlichkeit
                    $\nicefrac{1}{6}$) wird das neue Maximum auf $j$ gesetzt.
                    Da das neue Maximum nicht kleiner als das bisherige sein
                    kann, sind solche Übergänge ausgeschlossen.
                    Für die Einschritt-Übergangswahrscheinlichkeiten gilt also
                    \begin{equation*}
                        p_{ij} = \prob(X_2=j \ |\  X_1=i) =
                        \begin{cases}
                            \nicefrac{1}{6} & \text{if } j > i \\
                            \nicefrac{i}{6} & \text{if } j = i \\
                            0 & \text{if } j < i
                        \end{cases}
                        \qquad
                        \forall i,j \in \{1,2, \dotsc, 6\}
                    \end{equation*}
                    Das erste Element der Folge $X_1$ nimmt die Werte
                    gleichverteilt über $\{1,2, \dotsc, 6\}$ an.
                    Damit ist $(X_n)_{n \in \N}$ eine Markov-Kette.
                \end{proof}

        \end{enumerate}

    \item
        \begin{behaupt}
            Wenn eine Zufallsvariable $W$ Werte in $\N$ annimmt und
            \begin{equation*}
                \prob(W =k\ |\ W > n) = \prob(W = k - n)
            \end{equation*}
            für alle $n \in \N_0$ und alle $k
            \in \{n+1, n+2, \dotsc\}$ erfüllt, ist $W$ geometrisch verteilt mit
        einem Parameter $p \in (0, 1]$: $W \sim \text{Geom}_p$.
        \end{behaupt}

        %%     Für eine bessere Einsicht änderen wir die Betrachtung unserer 
        %%     Variable. Was wir zuvor als $k$ betrachteten, soll im Folgenden
        %%     $n+k$ heißen, wobei $k$ den Abstand zu $n$ aufzeigt, wodurch nun
        %%     $k \in \{1, 2, \dotsc\}$.
        %%     
        %%     Gegeben ist die somit die umformulierte Geleichung
        %%     \begin{equation*}
	    %%   \prob(W = n+k \ |\  W > n) = \prob(W = k)
        %%     \end{equation*}
        %%     Da dies für jede beliebige Kombination von $n,k$ gilt,
        %%     ist dadurch ersichtlich, dass die Wahrscheinlichkeit eines Wertes
	    %% allein vom Ausgangspunkt der Betrachtung abhängt. Für eine bessere
	    %% Einsicht, vergleiche oben stehenden Ausdruck mit
	    %% \begin{equation*}
	    %%   \prob(W = n+k \ |\  W > n) = \prob(W = k \ |\ W > 0)
        %%     \end{equation*}
        %%     Die Variable $n$ stellt also unseren Ausgangspunkt dar und die 
        %%     Wahrscheinlichkeit von einem Wert $n+k$ ist allein von der Größe $k$
        %%     abhängig.
        %%     
        %%     Wir betrachten Zufallsvariable $X_i$, welche auf $\{0,1\}$ abbilden.
        %%     Ein $X_i$ repräsentiert das Ergbnis eines Tests, ob $W>i$. Wobei wir 
        %%     die Einschritt-Übergangswahrscheinlichkeit mit $p$ angeben:
        %%     \begin{equation*}
	    %%   \prob(X_{n+1} = 1 \ |\  X_n = 1) = p
        %%     \end{equation*}
                        
        \begin{proof}
            Seien $j = k - n$ und $p = \prob(W = 1)$. Da $W$ auf $\N$ abbildet,
            folgt $\prob(W > 1) = 1 - p$.

            Zunächst zeigen wir, dass für $W$ genauso wie für eine geometrisch
            verteilte Zufallsvaraible $\prob(W > k) = (1-p)^k$ gilt.
            \begin{equation}
                \begin{alignedat}{2}
                    && \prob(W = k \ |\  W > n) &= \prob(W = k-n) \\
                    \gdw\ && \prob(W = n+j \ |\  W > n) &= \prob(W = j) \\
                    \stackrel{(\star)}{\gdw}\ && 
                    \prob(W > n+j \ |\  W > n) &= \prob(W > j) \\
                    \gdw\ && \frac{\prob(W > n+j,  W > n)}{\prob(W > n)}
                          &= \prob(W > j) \\
                    \gdw\ && \prob(W > n+j)
                          &= \prob(W > n) \cdot \prob(W > j) \\
                    \gdw\ && \prob(W > k) &= (\prob(W > 1))^k \\
                    \gdw\ && \prob(W > k) &= (1-p)^k
                \end{alignedat}
                \label{eq:memless1}
            \end{equation}
            In der mit $(\star)$ markierten Zeile wird verwendet, dass $\prob(W
            > j) = \sum_{i > j} \prob(W = i)$ gilt (analog für die linke
            Seite).

            Obiges Ergebnis verwenden wir nun, um die eigentliche Behauptung zu
            zeigen. Wir beginnen mit der zweiten Zeile von Gleichung
            \eqref{eq:memless1}, in der $j = 1$ und $n = x-1$ gesetzt werden.
            \begin{equation*}
                \begin{alignedat}{2}
                          && \prob(W = (x-1) + 1 \ |\  W > (x-1))
                          &= \prob(W = 1) \\
                    \gdw\ && \frac{\prob(W = (x-1) + 1, W > (x-1))}
                                  {\prob(W > (x-1))}
                          &= \prob(W = 1) \\
                    \gdw\ && \frac{\prob(W = x)}{\prob(W > x-1)}
                          &= \prob(W = 1) \\
                    \gdw\ && \prob(W = x)
                          &= \prob(W = 1) \cdot \prob(W > x-1) \\
                    \gdw\ && \prob(W = x)
                          &= p \cdot (1-p)^{x-1} \\
                    \gdw\ && \prob(W = x)
                          &= \text{Geom}_p(x)
                \end{alignedat}
            \end{equation*}
            Die Verteilung von $W$ ist also die geometrische Verteilung mit
            Parameter $p$: $W \sim \text{Geom}_p$.
        \end{proof}

\end{enumerate}


\end{document}
