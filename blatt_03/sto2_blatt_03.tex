\documentclass[a4paper]{scrartcl}

% font/encoding packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[ngerman]{babel}
\usepackage[ngerman=ngerman-x-latest]{hyphsubst}

\usepackage{amsmath, amssymb, amsfonts, amsthm}
\usepackage{array}
\usepackage{stmaryrd}
\usepackage{marvosym}
\allowdisplaybreaks
\usepackage[output-decimal-marker={,}]{siunitx}
\usepackage[shortlabels]{enumitem}
\usepackage[section]{placeins}
\usepackage{float}
\usepackage{units}
\usepackage{listings}
\usepackage{pgfplots}
\pgfplotsset{compat=1.12}
\usepackage{tikz}
\usetikzlibrary{arrows,automata}

\newtheorem*{behaupt}{Behauptung}
\newcommand{\gdw}{\Leftrightarrow}
\newcommand{\N}{\mathbb{N}}
\newcommand{\prob}{\mathbb{P}}
\newcommand{\cov}{\operatorname{Cov}}
\newcommand{\e}{\mathbb{E}}
\newcommand{\var}{\operatorname{Var}}
\newcommand{\corr}{\operatorname{Corr}}

\usepackage{fancyhdr}
\pagestyle{fancy}

\lstset{%
    frame=single,
    numbers=left,
    keepspaces,
    language=R,
    title=Listing: \lstname,
}

\def \blattnr {3}

\lhead{Stochastik 2 - Blatt {\blattnr}}
\rhead{Florian Abt, Lennart Braun, Sascha Schulz}
\cfoot{\thepage}


\title{Stochastik 2 für Informatiker}
\subtitle{Blatt {\blattnr} Hausaufgaben}
\author{
    Florian Abt (6524404), \\
    Lennart Braun (6523742), \\
    Sascha Schulz (6434677)
}
\date{zum 3. November 2015}

\begin{document}
\maketitle

\begin{enumerate}[label=\bfseries \blattnr.\arabic*]
    \item
        \begin{enumerate}[label=\alph*)]
            \item
                \begin{behaupt}
                    $x_i = 1$ für alle $i \in T$ ist eine Lösung des linearen
                    Gleichungssystems
                    \begin{equation*}
                        x_i = \sum_{c \in C} p_{ic} + \sum_{j \in T} p_{ij} x_j
                        \text{ .}
                    \end{equation*}
                \end{behaupt}
                \begin{proof}
                    Sei $x_i = 1$ für alle $i \in T$.
                    \begin{equation*}
                        \begin{split}
                            \sum_{c \in C} p_{ic} + \sum_{j \in T} p_{ij} x_j
                            &= \sum_{c \in C} p_{ic} + \sum_{j \in T} p_{ij} \\
                            &= \sum_{k \in E = C \cup T} p_{ik} \\
                            &= 1 = x_i
                        \end{split}
                    \end{equation*}
                \end{proof}

                \begin{behaupt}
                    Aus den drei Aussagen folgt die Behauptung.
                \end{behaupt}
                \begin{proof}
                    Wir wissen:
                    \begin{itemize}
                        \item
                            $x_i = \alpha_i(C)$ ist eine Lösung für das LGS.
                        \item
                            $x_i = 1$ ist eine Lösung für das LGS.
                        \item
                            Die Lösung ist eindeutig für jede Form der
                            Inhomogenität, also auch für $\gamma_i = \sum_{c
                            \in C} p_{ic}$.
                    \end{itemize}
                    Dann muss $\alpha_i(C) = x_i = 1$ für alle $i \in T$
                    gelten.
                \end{proof}

            \item
                \begin{behaupt}
                    $x_i = 1$ für $i \in \N$ ist eine Lösung für
                    \begin{equation*}
                        x_i = p_{i0} + \sum_{j=1}^\infty p_{ij} x_j
                        \text{ .}
                    \end{equation*}
                \end{behaupt}
                \begin{proof}
                    Sei $x_i = 1$ für alle $i \in \N$.
                    Zunächst betrachten wir den Fall $1 < i \in \N$.
                    \begin{equation*}
                        \begin{split}
                            p_{i0} + \sum_{j=1}^\infty p_{ij} x_j
                            &= 0 + p_{i,i-1} x_{i-1} + p_{i,i+1} x_{i+1} \\
                            &= (1-p) \cdot 1 + p \cdot 1 \\
                            &= (1-p) + p \\
                            &= 1 = x_i
                        \end{split}
                    \end{equation*}
                    Nun betrachten wir den Fall $i = 1$.
                    \begin{equation*}
                        \begin{split}
                            p_{i0} + \sum_{j=1}^\infty p_{ij} x_j
                            &= p_{1,0} + p_{1,2} x_{2} \\
                            &= (1-p)  + p \cdot 1 \\
                            &= (1-p) + p \\
                            &= 1 = x_1
                        \end{split}
                    \end{equation*}
                    $x_i = 1$ für alle $i \in \N$ ist also eine Lösung des
                    linearen Gleichungssystems.
                \end{proof}

                \begin{behaupt}
                    $x_i = \left(\frac{1-p}{p}\right)^i$ für $i \in \N$ ist
                    eine Lösung für
                    \begin{equation*}
                        x_i = p_{i0} + \sum_{j=1}^\infty p_{ij} x_j
                        \text{ .}
                    \end{equation*}
                \end{behaupt}
                \begin{proof}
                    Sei $x_i = \left(\frac{1-p}{p}\right)^i$ für alle $i \in
                    \N$.  Zunächst betrachten wir den Fall $1 < i \in \N$.
                    \begin{equation*}
                        \begin{split}
                            p_{i0} + \sum_{j=1}^\infty p_{ij} x_j
                            &= 0 + p_{i,i-1} x_{i-1} + p_{i,i+1} x_{i+1} \\
                            &= (1-p) \left( \frac{1-p}{p} \right)^{i-1} +
                                p \left( \frac{1-p}{p} \right)^{i+1} \\
                            &= \left( \frac{1-p}{p} \right)^{i-1}
                                \left( (1-p) + 
                                p \left( \frac{1-p}{p} \right)^{2} \right) \\
                            &= \left( \frac{1-p}{p} \right)^{i-1}
                                \left( (1-p) + \frac{(1-p)^2}{p} \right) \\
                            &= \left( \frac{1-p}{p} \right)^{i-1}
                                \left( \frac{p -p^2 +1 -2p +p^2}{p} \right) \\
                            &= \left( \frac{1-p}{p} \right)^{i-1}
                                \left( \frac{1-p}{p} \right) \\
                            &= \left( \frac{1-p}{p} \right)^i = x_i
                        \end{split}
                    \end{equation*}
                    Nun betrachten wir den Fall $i = 1$.
                    \begin{equation*}
                        \begin{split}
                            p_{i0} + \sum_{j=1}^\infty p_{ij} x_j
                            &= p_{1,0} + p_{1,2} x_{2} \\
                            &= (1-p) + p \cdot \left(\frac{1-p}{p}\right)^2 \\
                            &= (1-p) + \frac{(1-p)^2}{p} \\
                            &= \frac{p -p^2 +1 -2p +p^2}{p} \\
                            &= \frac{1-p}{p} \\
                            &= \left(\frac{1-p}{p}\right)^1 = x_1
                        \end{split}
                    \end{equation*}
                    $x_i = \left(\frac{1-p}{p}\right)^i$ für alle $i \in \N$
                    ist also eine Lösung des linearen Gleichungssystems.
                \end{proof}

            \item
                Wir halten $x_i = \left( \frac{1-p}{p} \right)^i$ ($\forall i
                \in \N$) für die „glaubhaftere“ Lösung.

                Die Wahrscheinlichkeit, das Spiel mit einem Startkapital von
                $a$ zu verlieren, also in den Zustand $0$ zugelangen, wurde in
                der Vorlesung mit
                \begin{equation*}
                    \alpha_a(0)
                    = 1 - \frac{1 - \left( \frac{1-p}{p} \right)^a}
                               {1 - \left( \frac{1-p}{p} \right)^{a+b}}
                \end{equation*}
                angegeben. $b$ sei hierbei das Startkapital des Gegenspielers.
                Da $\frac{1-p}{p} < 1$ gilt $\left( \frac{1-p}{p} \right)^{a+b}
                \to 0$ für $b \to \infty$.
                Für den Grenzwert der Absorbtionswahrscheinlichkeit ergibt sich
                \begin{equation*}
                    \begin{split}
                        \lim_{b \to \infty} \alpha_a(0)
                        &= 1 - \frac{1 - \left( \frac{1-p}{p} \right)^a}
                                    {1 - 0} \\
                        &= \left( \frac{1-p}{p} \right)^a = x_a
                        \text{ .}
                    \end{split}
                \end{equation*}

        \end{enumerate}

   \item
   
    \begin{enumerate}
     \item TODO: Varianz?!
     \item
	Wir wählen eine Zufallsvariable Y, welche die Anzahl der Schritte bis zum erreichen eines absorbierenden Zustands zählt.
	
	Folglich ist $\mathbb{E}(\tau|X_0=i) = \mathbb{E}(Y|X_0=i)$, wobei
	
	\begin{equation*}
	  \begin{split}
	    \mathbb{E}(Y|X_0=i) 
		&= \sum_{n=1}^\infty \mathbb{P}(Y=n|X_0=i) \cdot n \\
		&= 1 + \sum_{n=1}^\infty \sum_{j\in T} \mathbb{P}(Y=n, X_1=j | X_0=i) \cdot n \\
		&= 1 + \sum_{j\in T} \sum_{n=1}^\infty \mathbb{P}(Y=n|X_1 = j, X_0=i) \cdot \mathbb{P}(X_1=j|X_0=i) \cdot n \\
		&= 1 + \sum_{j\in T} \sum_{n=1}^\infty \mathbb{P}(Y=n|X_1 = j) \cdot p_{ij} \cdot n \\
		&= 1 + \sum_{j\in T} p_{ij} \cdot \sum_{n=1}^\infty \mathbb{P}(Y=n|X_0=j) \cdot n \\
		&= 1 + \sum_{j\in T} p_{ij} \cdot \mathbb{E}(Y|X_0=j)
	  \end{split}
	\end{equation*}
	
	Wobei $\mathbb{E}(Y|X_0=j)$ dem $m_j$ entspricht.
	
	Da $m_c = \mathbb{E}(Y|X_0=c) = 0$ gegeben ist, kann dies verallgemeinert werden:
	$$ \mathbb{E}(Y|X_0=i) = 1 + \sum_{j\in T} p_{ij} \cdot \mathbb{E}(Y|X_0=j) = 1 + \sum_{j\in E} p_{ij} \cdot \mathbb{E}(Y|X_0=j)$$
	da durch die Multiplikation mit dem Faktor 0 alle Therme für $c \in C$ ignoriert werden, welche durch die Erweiterung hinzukommen, da gerade $E\setminus T=C$.

    \end{enumerate}

   

   \item 
   
     Eine Invariante Verteilung setzt vorraus, dass $\pi = \pi \cdot P$,\\ wobei $\pi$ ein stochstischer Vektor ist.
   
     \begin{enumerate}
      \item
	\begin{equation*}
	 \pi = \pi \cdot P \\
	 \end{equation*}
	 \begin{equation*}
	  \begin{pmatrix}
	   p_1 & p_2 & p_3
	  \end{pmatrix}
	  =
	  \begin{pmatrix}
	   p_1 & p_2 & p_3
	  \end{pmatrix}
	  \cdot
	  \begin{pmatrix}
	    0 & \frac23 & \frac13 \\
	    \frac13 & 0 & \frac23 \\
	    \frac23 & \frac13 & 0 
	  \end{pmatrix}
	\end{equation*}

      Daraus ergiebt sich das LGS:
      
      \begin{equation}
       p_1 = \frac13 p_2 + \frac23 p_3 
      \end{equation}
      \begin{equation}
       p_2 = \frac23 p_1 + \frac13 p_3 
      \end{equation}       
      \begin{equation}
	p_3 = \frac13 p_1 + \frac23 p_2
      \end{equation}       
           
      \begin{equation}
	\begin{split}
       \Rightarrow p_1 &= \frac13 p_2 + \frac23 \left(\frac13 p_1 + \frac23 p_2\right) \\
       \Rightarrow p_1 &= \frac13 p_2 + \frac29 p_1 + \frac49 p_2 \\
       \Rightarrow \frac79 p_1 &= \frac79 p_2 \\
       \Rightarrow p_1 &= p_2 \\
       \Rightarrow p_3 &= \frac13 p_1 + \frac23 p_1 \\
       \Rightarrow p_3 &= p_1
	\end{split}
      \end{equation}
      
      Folglich ist $\pi = \left(\frac13,\frac13,\frac13\right)$ die eindeutige invariante Verteilung. 
      
      Da $p_{ij} > 0$ für $i\neq j$ ist jedes Ereignis mit einem Schritt aus jedem anderen Ereignis erreichbar, somit ist
      der Ereignisraum irreduzibel.
      
      Da zusätzlich auch $p_{ii}=0$ gilt, ist direkt ersichtlich, dass jedes Ereignis periodisch
      mit $d_i=2$ ist, folglich ist $(X_n)_{n\in\N_0}$ periodisch.	
	
      \item
	\begin{equation*}
	 \pi = \pi \cdot P \\
	 \end{equation*}
	 \begin{equation*}
	  \begin{pmatrix}
	   p_1 & p_2 & p_3
	  \end{pmatrix}
	  =
	  \begin{pmatrix}
	   p_1 & p_2 & p_3
	  \end{pmatrix}
	  \cdot
	  \begin{pmatrix}
	    \frac14 & 0 & \frac34 \\
	    0 & 1 & 0 \\
	    \frac12 & 0 & \frac12 
	  \end{pmatrix}
	\end{equation*}

      Daraus ergiebt sich das Gleichungssystem:
      
      \begin{equation} \label{eq:3.3.b.I}
       p_1 = \frac14 p_1 + \frac12 p_3 \Rightarrow \frac34 p_1 = \frac12 p_3 \Rightarrow p_1 = \frac23 p_3
      \end{equation}
      \begin{equation}
       p_2 = p_2 
      \end{equation}       
      \begin{equation} \label{eq:3.3.b.III}
	p_3 = \frac34 p_1 + \frac12 p_3
      \end{equation}       

      Folglich ist $\pi=\left(k,c,\frac23k\right)$ mit $1 = c + \frac53k$  die invariante Veteilung.
      
      Irreduzibilität nicht gegeben. Zum einen, da das Ereignis 2 absorbierend 
      und somit von ihm aus gehend kein anderer erreichbar ist.
      
      Für das Ereignis 2 ist durch die Absorbtion keine Periodizität gegeben; 
      da $p_{ii}>0$ für $i \in E\setminus\{2\}$ sind alle anderen Ereignisse aperiodisch.
      
      
	
      \item
      
      \begin{equation*}
	 \pi = \pi \cdot P \\
	 \end{equation*}
	 \begin{equation*}
	  \begin{pmatrix}
	   p_1 & p_2 & p_3
	  \end{pmatrix}
	  =
	  \begin{pmatrix}
	   p_1 & p_2 & p_3
	  \end{pmatrix}
	  \cdot
	  \begin{pmatrix}
	    0 & \frac14 & \frac34 \\
	    1 & 0 & 0 \\
	    1 & 0 & 0
	  \end{pmatrix}
	\end{equation*}

      Daraus ergiebt sich das Gleichungssystem:
      
      \begin{equation} \label{3.3.c.I}
       p_1 = p_2 + p_3
      \end{equation}
      \begin{equation} \label{3.3.c.II}
       p_2 = \frac14 p_1
      \end{equation}       
      \begin{equation} \label{3.3.c.III}
	p_3 = \frac34 p_1
      \end{equation}  
      
      Hieraus lässt sich die invariante Verteilung $\pi = \left(\frac12, \frac18, \frac38\right)$ ablesen, welche eindeutig ist.
      
      Der Zustandsraum $E$ ist irreduzibel, da aus den Gleichungen (\ref{3.3.c.I}) bis (\ref{3.3.c.III}) ersichtlich wird, dass jedes Ereignis von 
      jedem anderen Ereignis in maximal 2 Schritten erreicht werden kann.
      
      Betrachten wir die Periodizität der einzelnen Zustände, ergibt sich analog zu vorhergehender Aussage:
      
      $p^{(n)}_{ii}$ mit n = 
      $\begin{cases} 
	\{ 2,4,6,\ldots \} &, i = 1 \\
	\{ 2,4,6,\ldots\} &, i = 2 \\
	\{ 2,4,6,\ldots\} &, i = 3
      \end{cases}
      $
      
      Folglich haben alle Ereignisse die gleiche Periodizität $d_i=2$ und somit ist $(X_n)_{n\in\N_0}$ periodisch.
     \end{enumerate}


\end{enumerate}


\end{document}
